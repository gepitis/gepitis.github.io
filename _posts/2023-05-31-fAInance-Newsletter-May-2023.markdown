---
layout: default
title:  "fAInance Newsletter - May 2023"
date:   2023-05-31 05:35:34 +0100 
categories: jekyll update
---

# fAInance Newsletter - May 2023
  
## ML for Finance/Quant:
 <details><summary><a href="https://arxiv.org/abs/2305.01505">Beyond Classification: Financial Reasoning in State-of-the-Art Language Models</a></summary>This research explores the application of Large Language Models (LLMs) with 100 billion or more parameters in the financial domain. The study demonstrates that LLMs with 6B parameters or more, combined with instruction-tuning and larger datasets, exhibit the ability to generate coherent financial reasoning, contributing to the understanding of the efficacy of language models in the field of finance and investment decision-making.</details>
 <details><summary><a href="https://www.sciencedirect.com/science/article/abs/pii/S0022199623000594">Credit growth, the yield curve and financial crisis prediction: Evidence from a machine learning approach☆</a></summary>The paper develops early warning models for financial crisis prediction using machine learning on macrofinancial data for 17 countries from 1870 to 2016. Machine learning models outperform traditional regression in forecasting crises, and credit growth and the slope of the yield curve (both domestically and globally) are identified as the most crucial predictors. The study's unique approach using the Shapley value framework provides economic insights and interprets the complex relationships between predictors and crisis risk.</details>
 <details><summary><a href="https://www.cell.com/heliyon/pdf/S2405-8440(23)03362-5.pdf">Optimization of investment strategies through machine learning</a></summary>This research endeavors to devise an advanced and sustainable stock quantitative investing model, employing a fusion of Machine Learning techniques and Economic Value-Added methodologies to optimize investment strategies, with a focus on quantitative stock selection through principal component analysis and economic value-added criteria, and algorithmic trading utilizing Moving Average Convergence, Stochastic Indicators, and Long-Short Term Memory, achieving superior forecasting accuracy with LSTM networks and outperforming the market by generating considerable returns, thus proving its viability for rational and profitable investing in various market situations. </details>
 <details><summary><a href="https://onlinelibrary.wiley.com/doi/full/10.1111/mafi.12382">Recent advances in reinforcement learning in finance</a></summary>The finance industry has undergone significant changes due to the abundance of data, leading to advancements in data processing and analysis. Reinforcement learning (RL) has emerged as a powerful tool in making financial decisions by leveraging large datasets with fewer model assumptions. Unlike traditional stochastic control theory, RL methods can handle complex financial environments and improve decision-making without heavily relying on specific model assumptions. This survey paper provides an overview of recent developments and applications of RL in finance, covering various algorithms, including value- and policy-based methods, and their connection with neural networks. The paper explores how RL techniques are applied in decision-making problems in finance, such as optimal execution, portfolio optimization, option pricing and hedging, market making, smart order routing, and robo-advising. The survey concludes by suggesting potential future research directions in this rapidly evolving field.</details>
 <details><summary><a href="https://arxiv.org/abs/2305.03835">Spatiotemporal Transformer for Stock Movement Prediction</a></summary>The finance industry has undergone significant changes due to the abundance of data, leading to advancements in data processing and analysis. Reinforcement learning (RL) has emerged as a powerful tool in making financial decisions by leveraging large datasets with fewer model assumptions. Unlike traditional stochastic control theory, RL methods can handle complex financial environments and improve decision-making without heavily relying on specific model assumptions. This survey paper provides an overview of recent developments and applications of RL in finance, covering various algorithms, including value- and policy-based methods, and their connection with neural networks. The paper explores how RL techniques are applied in decision-making problems in finance, such as optimal execution, portfolio optimization, option pricing and hedging, market making, smart order routing, and robo-advising. The survey concludes by suggesting potential future research directions in this rapidly evolving field.</details>
 <details><summary><a href="https://arxiv.org/pdf/2303.13216.pdf">A Case Study on AI Engineering Practices: Developing an Autonomous Stock Trading System</a></summary>This paper presents a case study on the development of an autonomous stock trading system using machine learning. It applies 10 AI engineering practices, documenting their effectiveness and challenges faced during development. The study aims to provide practical insights for AI engineering teams and newcomers in the field, contributing to the emerging body of evidence in AI engineering.</details>
 <details><summary><a href="https://arxiv.org/pdf/2305.16364.pdf">E2EAI: End-to-End Deep Learning Framework for Active Investing</a></summary>This paper introduces E2EAI, an end-to-end deep learning framework for active investing in the financial market. The framework covers factor selection, stock selection, and portfolio construction, optimizing portfolio returns subject to constraints. It utilizes a gated-attention mechanism for factor selection and portfolio construction, and a deep multifactor model with a directional estimator to interpret the deep factor. The framework is validated with real data, outperforming existing investment pipelines with separately optimized modules. The proposed E2E approach improves portfolio construction and provides insights into the relationship between original factors and the deep factor used in portfolio construction.</details>
 <details><summary><a href="https://arxiv.org/pdf/2305.14368.pdf">Support for Stock Trend Prediction Using Transformers and Sentiment Analysis</a></summary>This paper presents a Transformer-based model for accurate stock trend prediction using technical stock data and sentiment analysis. The model outperforms conventional Recurrent Neural Networks (RNNs) in capturing long-term dependencies and accounting for the impact of breaking news on stock movements. The experiments show significant improvements in directional accuracy, up to 18.63%, when using longer time sequences. The proposed model's performance is compared to RNNs for various trading strategies, demonstrating its effectiveness in predicting stock trends.</details>

 <a href="https://gmarti.gitlab.io//qfin/2023/05/28/qpm-stat-arb.html">[Active Reading with ChatGPT] Quantitative Portfolio Management: The Art and Science of Statistical Arbitrage</a>
 <a href="https://gmarti.gitlab.io//quant/2023/05/07/wikipedia-network-companies-sentence-transformers.html">Building a S&P 500 company classification from Wikipedia articles (guided by ChatGPT)</a>
  
## General ML:
 <details><summary><a href="https://arxiv.org/abs/2206.14486v1">Beyond neural scaling laws: beating power law scaling via data pruning</a></summary>The paper discusses neural scaling laws in deep learning, where error reduction follows a power law with increased training data or model size. However, this approach requires significant compute and energy costs. The paper proposes an alternative strategy of data pruning, where datasets are reduced while maintaining performance. The authors present a theoretical framework and empirical results showing that exponential scaling is achievable with data pruning, and they introduce a new self-supervised pruning metric that performs well without requiring labeled data. This work suggests that intelligent data pruning could lead to more resource-efficient deep learning.</details>
 <details><summary><a href="https://arxiv.org/abs/2304.12526">Patch Diffusion: Faster and More Data-Efficient Training of Diffusion Models</a></summary>The paper introduces Patch Diffusion, a new training framework for diffusion models that significantly reduces training time and improves data efficiency. By learning a conditional score function at the patch level, incorporating patch location information, and diversifying patch sizes throughout training, Patch Diffusion achieves more than 2× faster training while maintaining comparable or better generation quality. The approach democratizes diffusion model training, making it more accessible to researchers who lack high-end computational resources. Patch Diffusion also shows competitive results and notable performance gains even with small training datasets.</details>
 <details><summary><a href="https://developer.nvidia.com/blog/why-automatic-augmentation-matters/">Why Automatic Augmentation Matters</a></summary>Automatic data augmentation methods, such as AutoAugment and RandAugment, have emerged to reduce the reliance on manual data preprocessing for deep learning models. NVIDIA DALI, a powerful library, provides GPU-accelerated capabilities for data preprocessing, overcoming bottlenecks and improving training throughput. The library offers ready-to-use implementations of popular automatic augmentations, allowing for efficient training with diverse and augmented data. By moving data loading and augmentation to the GPU, DALI overcomes preprocessing bottlenecks, increasing GPU utilization and speeding up training times. Overall, automatic data augmentation with NVIDIA DALI provides an effective and efficient approach to diversify datasets and improve model accuracy in deep learning applications.
</details>

  
## Language Models:
 <details><summary><a href="https://www.spectator.co.uk/article/we-may-be-history-geoffrey-hinton-on-the-dangers-of-ai/?utm_source=ONTRAPORT-email-broadcast&utm_medium=ONTRAPORT-email-broadcast&utm_term=Newsletter&utm_content=Data+Science+Insider%3A+May+5th%2C+2023&utm_campaign=06052023
">The godfather of AI: why I left Google</a></summary>Geoffrey Hinton, a prominent figure in AI, has expressed concerns that AI could pose an existential threat to humanity and may replace us as the dominant form of intelligence. He points out the potential dangers of digital intelligence developing sub-goals that do not align with human objectives, making us vulnerable to AI manipulation. Hinton believes that AI's ability to create more copies of itself could lead to a competitive evolution among AGI, potentially leading to the extinction of less powerful forms of intelligence.</details>
<details><summary><a href="https://huggingface.co/blog/starcoder">StarCoder: A State-of-the-Art LLM for Code</a></summary>StarCoder and StarCoderBase are Large Language Models (LLMs) for code, trained on GitHub data and programming languages. They outperform existing open Code LLMs on various benchmarks and can process more input than any other open LLM, making them suitable for diverse applications, such as acting as a technical assistant, code autocompletion, code modification, and code explanation. StarCoder has undergone evaluations, surpassing other models in performance, and it is released under the OpenRAIL license, ensuring safety and ease of integration into products.</details>

  
## Miscellaneous:

<a href="https://www.modular.com/mojo">Mojo programming language for AI</a>

<a href="https://github.com/gventuri/pandas-ai">Pandas AI toolbox</a>

<a href="https://github.com/togethercomputer/OpenChatKit">OpenChatKit</a>
  
## Upcoming Conferences/Deadlines:

